import io
import json
import os
import pandas as pd
import streamlit as st
import requests
import base64
from datetime import datetime

st.set_page_config(page_title="ì—‘ì…€ ì…ì¶œê³  ë¶„ë¥˜ê¸°", layout="centered")
st.title("ğŸ“¦ ì •ì‚°ìš© ì…ì¶œê³  ë‚´ì—­ ìë™ ë¶„ë¥˜ê¸°")

# --- GitHub ì„¤ì • ---
GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN", "")  # Streamlit Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
GITHUB_REPO = st.secrets.get("GITHUB_REPO", "")     # ì˜ˆ: "username/repo-name"
GITHUB_FILE_PATH = "market_products.json"           # GitHub ì €ì¥ ê²½ë¡œ

# --- GitHub API í•¨ìˆ˜ ---
def get_file_from_github():
    """GitHubì—ì„œ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°"""
    if not GITHUB_TOKEN or not GITHUB_REPO:
        return []
    
    url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{GITHUB_FILE_PATH}"
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Accept": "application/vnd.github.v3+json"
    }
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            content = response.json()
            file_content = base64.b64decode(content['content']).decode('utf-8')
            return json.loads(file_content)
        elif response.status_code == 404:
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return []
        else:
            st.warning(f"GitHubì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {response.status_code}")
            return []
    except Exception as e:
        st.warning(f"GitHub ì—°ê²° ì˜¤ë¥˜: {e}")
        return []

def save_file_to_github(products, sha=None):
    """GitHubì— íŒŒì¼ ì €ì¥í•˜ê¸°"""
    if not GITHUB_TOKEN or not GITHUB_REPO:
        st.error("âš ï¸ GitHub ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. Streamlit Secretsì— GITHUB_TOKENê³¼ GITHUB_REPOë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return False
    
    url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/{GITHUB_FILE_PATH}"
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Accept": "application/vnd.github.v3+json"
    }
    
    # JSONì„ base64ë¡œ ì¸ì½”ë”©
    content = json.dumps(products, ensure_ascii=False, indent=2)
    content_bytes = content.encode('utf-8')
    content_base64 = base64.b64encode(content_bytes).decode('utf-8')
    
    # í˜„ì¬ íŒŒì¼ì˜ SHA ê°€ì ¸ì˜¤ê¸° (ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ í•„ìš”)
    if sha is None:
        try:
            get_response = requests.get(url, headers=headers)
            if get_response.status_code == 200:
                sha = get_response.json()['sha']
        except:
            pass
    
    # ì»¤ë°‹ ë°ì´í„°
    data = {
        "message": f"ë§ˆì¼“ ìƒí’ˆëª… ì—…ë°ì´íŠ¸ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "content": content_base64,
        "branch": "main"  # ë˜ëŠ” "master" (ë³¸ì¸ì˜ ê¸°ë³¸ ë¸Œëœì¹˜ì— ë§ê²Œ)
    }
    
    if sha:
        data["sha"] = sha
    
    try:
        response = requests.put(url, headers=headers, json=data)
        if response.status_code in [200, 201]:
            return True
        else:
            st.error(f"GitHub ì €ì¥ ì‹¤íŒ¨: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        st.error(f"GitHub ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

# --- ë§ˆì¼“ ìƒí’ˆëª… ê´€ë¦¬ ---
# ì´ˆê¸° ë¡œë“œ (GitHubì—ì„œ ê°€ì ¸ì˜¤ê¸°)
if 'market_products' not in st.session_state:
    st.session_state.market_products = get_file_from_github()
if 'github_sha' not in st.session_state:
    st.session_state.github_sha = None

st.write("### 1) ë§ˆì¼“ ìƒí’ˆëª… ê´€ë¦¬")

# GitHub ì—°ê²° ìƒíƒœ í‘œì‹œ
if GITHUB_TOKEN and GITHUB_REPO:
    st.success(f"âœ… GitHub ì—°ê²°ë¨: `{GITHUB_REPO}`")
else:
    st.warning("âš ï¸ GitHub ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¡œì»¬ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.")
    with st.expander("ğŸ“– GitHub ì„¤ì • ë°©ë²• ë³´ê¸°"):
        st.markdown("""
        ### Streamlit Cloudì—ì„œ GitHub ì—°ë™ ì„¤ì •
        
        1. **Streamlit Cloud ëŒ€ì‹œë³´ë“œ** ì ‘ì†
        2. ì•± ì„ íƒ â†’ **Settings** â†’ **Secrets**
        3. ë‹¤ìŒ ë‚´ìš© ì…ë ¥:
        ```toml
        GITHUB_TOKEN = "ghp_your_token_here"
        GITHUB_REPO = "username/repository-name"
        ```
        4. **Save** í´ë¦­
        
        ### ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸í•  ë•Œ
        í”„ë¡œì íŠ¸ í´ë”ì— `.streamlit/secrets.toml` íŒŒì¼ ìƒì„± í›„ ê°™ì€ ë‚´ìš© ì…ë ¥
        """)

# íƒ­ìœ¼ë¡œ êµ¬ë¶„: ì¶”ê°€ / ëª©ë¡ ê´€ë¦¬
tab1, tab2 = st.tabs(["â• ìƒí’ˆëª… ì¶”ê°€", "ğŸ“‹ ë“±ë¡ëœ ìƒí’ˆëª…"])

with tab1:
    st.write("**ìƒˆë¡œìš´ ë§ˆì¼“ ìƒí’ˆëª…ì„ í•œ ì¤„ì— í•˜ë‚˜ì”© ì…ë ¥í•˜ì„¸ìš”** (ì—¬ëŸ¬ ê°œ ë™ì‹œ ì…ë ¥ ê°€ëŠ¥)")
    new_products_text = st.text_area(
        "ìƒí’ˆëª… ì…ë ¥",
        height=150,
        placeholder="ì˜ˆì‹œ:\ní…Œë¼í• ì•°í”Œ\nìºë¹„ì§„ì €\ní…Œë¼ë“œë¦¼ ìˆ˜ë©´ì˜ì–‘ì œ"
    )
    
    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("âœ… ì¶”ê°€í•˜ê¸°", type="primary"):
            if new_products_text.strip():
                # ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì¶”ê°€
                new_items = [
                    line.strip() 
                    for line in new_products_text.split('\n') 
                    if line.strip()
                ]
                
                # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
                added_count = 0
                for item in new_items:
                    if item not in st.session_state.market_products:
                        st.session_state.market_products.append(item)
                        added_count += 1
                
                if added_count > 0:
                    # GitHubì— ì €ì¥
                    with st.spinner("GitHubì— ì €ì¥ ì¤‘..."):
                        if save_file_to_github(st.session_state.market_products, st.session_state.github_sha):
                            st.success(f"âœ… {added_count}ê°œ ìƒí’ˆëª…ì´ ì¶”ê°€ë˜ê³  GitHubì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            # SHA ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ë‹¤ì‹œ ë¡œë“œ
                            st.session_state.market_products = get_file_from_github()
                            st.rerun()
                        else:
                            st.error("âŒ GitHub ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œì»¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")
                else:
                    st.info("â„¹ï¸ ëª¨ë‘ ì´ë¯¸ ë“±ë¡ëœ ìƒí’ˆëª…ì…ë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ ìƒí’ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

with tab2:
    if st.session_state.market_products:
        st.write(f"**í˜„ì¬ ë“±ë¡ëœ ë§ˆì¼“ ìƒí’ˆëª…: {len(st.session_state.market_products)}ê°œ**")
        
        # ë²„íŠ¼ë“¤
        col1, col2, col3 = st.columns([1, 1, 3])
        with col1:
            if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
                st.session_state.market_products = get_file_from_github()
                st.success("GitHubì—ì„œ ìµœì‹  ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
                st.rerun()
        
        with col2:
            if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ"):
                st.session_state.market_products = []
                with st.spinner("GitHubì— ì €ì¥ ì¤‘..."):
                    save_file_to_github([])
                st.rerun()
        
        # ì—‘ì…€ ë‚´ë³´ë‚´ê¸°
        st.write("---")
        export_df = pd.DataFrame(st.session_state.market_products, columns=['ë§ˆì¼“ ìƒí’ˆëª…'])
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            export_df.to_excel(writer, index=False, sheet_name='ë§ˆì¼“ìƒí’ˆëª…')
        buffer.seek(0)
        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ë¡œ ë‚´ë³´ë‚´ê¸°",
            data=buffer.getvalue(),
            file_name="ë§ˆì¼“ìƒí’ˆëª….xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_market"
        )
        
        # ìƒí’ˆëª… ëª©ë¡ í‘œì‹œ (ê°œë³„ ì‚­ì œ ê°€ëŠ¥)
        st.write("---")
        st.write("**ë“±ë¡ëœ ìƒí’ˆëª… ëª©ë¡:**")
        for idx, product in enumerate(st.session_state.market_products):
            col1, col2 = st.columns([5, 1])
            with col1:
                st.write(f"{idx+1}. {product}")
            with col2:
                if st.button("âŒ", key=f"del_{idx}"):
                    st.session_state.market_products.pop(idx)
                    with st.spinner("GitHubì— ì €ì¥ ì¤‘..."):
                        save_file_to_github(st.session_state.market_products, st.session_state.github_sha)
                    st.rerun()
    else:
        st.info("ğŸ“ ë“±ë¡ëœ ë§ˆì¼“ ìƒí’ˆëª…ì´ ì—†ìŠµë‹ˆë‹¤. 'ìƒí’ˆëª… ì¶”ê°€' íƒ­ì—ì„œ ì¶”ê°€í•´ì£¼ì„¸ìš”.")

# ë§ˆì¼“ ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
market_sales_list = st.session_state.market_products

st.divider()

# --- 2. ì…ì¶œê³  ì—‘ì…€ íŒŒì¼ë“¤ ì—…ë¡œë“œ ---
st.write("### 2) ì…ì¶œê³  ì—‘ì…€ íŒŒì¼ë“¤ ì—…ë¡œë“œ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)")
uploaded_files = st.file_uploader(
    "ì¶œê³ Â·ì…ê³  ì—‘ì…€(.xls/.xlsx) íŒŒì¼ì„ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”",
    type=["xls", "xlsx"],
    accept_multiple_files=True
)

# --- 3. 'ì •ë¦¬ ì—¬ë¶€' í™•ì¸ ---
if not market_sales_list:
    st.warning("âš ï¸ ë¨¼ì € ë§ˆì¼“ ìƒí’ˆëª…ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()

if not uploaded_files:
    st.info("â–¶ ì…ì¶œê³  íŒŒì¼ì„ ì—…ë¡œë“œí•œ ë’¤, ë¶„ë¥˜ ì‘ì—…ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

response = st.radio(
    "ë§ˆì¼“ ì¶œê³ ê±´ë“¤ì€ ìƒí’ˆëª…ì„ ì •ë¦¬í•˜ì…¨ë‚˜ìš”?",
    ["ì •ë¦¬í•¨", "ì•„ì§ ì•ˆí•¨"]
)
if response == "ì•„ì§ ì•ˆí•¨":
    st.warning("â— ë§ˆì¼“ ì¶œê³ ê±´ì„ ì •ë¦¬í•œ ë’¤ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- 4. ì»¬ëŸ¼ ê·¸ë£¹ ì •ì˜ ---
column_group_out = [
    'ì¶œê³ ì¼', 'êµ¬ë¶„', 'íŒë§¤ì²˜', 'ìƒí’ˆëª…', 'ê°€ìš©ì¶œê³ ìˆ˜ëŸ‰',
    'ë¹„ê³ ', 'ìˆ˜ë ¹ì', 'íŒë§¤ì²˜ìƒí’ˆëª…', 'íŒë§¤ì²˜ì˜µì…˜ëª…', 'ì¶œê³ ë°©ì‹']

column_group_in = [
    "ì…ê³ ì¼", "êµ¬ë¶„", "ê³µê¸‰ì²˜", "ìƒí’ˆëª…", "ê°€ìš©ì…ê³ ìˆ˜ëŸ‰",
    "ë¹„ê³ ", "ì˜µì…˜ì½”ë“œ", "ì…ê³ ë‹¨ê°€","ë°•ìŠ¤ìˆ˜ëŸ‰"]

# --- 5. ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜ ---
def classify(row, market_list):
    êµ¬ë¶„ = str(row.get('êµ¬ë¶„', '')).strip()
    ë¹„ê³  = str(row.get('ë¹„ê³ ', ''))

    # ë¹„ê³  ìš°ì„  ì²´í¬
    if "ë°€í¬ëŸ°" in ë¹„ê³ :
        return "ë¡œì¼“"
    if "ë¡œì¼“ê·¸ë¡œìŠ¤" in ë¹„ê³ :
        return "ë¡œì¼“"
    if "íŒŒìŠ¤í† " in ë¹„ê³ :
        return "ë¡œì¼“"
    if "ìŠ¤íƒ€ë°°ì†¡" in ë¹„ê³ :
        return "ë¡œì¼“"
    if "ì»¬ë¦¬" in ë¹„ê³ :
        return "ë¡œì¼“"
    if "ì˜¬ë¦¬ë¸Œì˜" in ë¹„ê³ :
        return "B2B"
    if "ì‹ ë¼ë©´ì„¸ì " in ë¹„ê³ :
        return "B2B"
    if "íí…" in ë¹„ê³ :
        return "B2B"
    if "ìˆ˜ì¶œ" in ë¹„ê³ :
        return "B2B"

    if êµ¬ë¶„ == "(-)ì¡°ì •":
        if "ì„¸íŠ¸" in ë¹„ê³ :
            return "ì„¸íŠ¸ìš© ì¶œê³ "
        else:
            return "ì¶œê³ ì¡°ì •"

    if êµ¬ë¶„ == "(+)ì¡°ì •":
        if "ì„¸íŠ¸" in ë¹„ê³ :
            return "ì„¸íŠ¸ìš© ì…ê³ "
        elif "ê°€êµ¬ë§¤" in ë¹„ê³ :
            return "ê°€êµ¬ë§¤ ì…ê³ "
        else:
            return "ì…ê³ ì¡°ì •"

    if êµ¬ë¶„ == "ì •ìƒì…ê³ ":
        if "ì„¸íŠ¸" in ë¹„ê³ :
            return "ì„¸íŠ¸ìš© ì…ê³ "
        else:
            return "ì •ìƒì…ê³ "

    if êµ¬ë¶„ == "ë°˜í’ˆì…ê³ ":
        return "ë°˜í’ˆì…ê³ "

    if êµ¬ë¶„ == "ì •ìƒì¶œê³ ":
        íŒë§¤ì²˜ = str(row.get('íŒë§¤ì²˜', '')).strip()
        íŒë§¤ì²˜ìƒí’ˆëª… = str(row.get('íŒë§¤ì²˜ìƒí’ˆëª…', '')).strip()
        íŒë§¤ì²˜ì˜µì…˜ëª… = str(row.get('íŒë§¤ì²˜ì˜µì…˜ëª…', ''))
        ì¶œê³ ë°©ì‹ = str(row.get('ì¶œê³ ë°©ì‹', '')).strip()

        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘
        result = "ì¼ë°˜"

        # ìš°ì„ ìˆœìœ„: ì•„ë˜ ì¡°ê±´ì´ ìœ„ ì¡°ê±´ì„ ë®ì–´ì”€

        # 11. ë¯¸ë¶„ë¥˜ ì¡°ê±´
        if (íŒë§¤ì²˜ == 'ì•„ì„ì›¹_ë¯¸ì˜¤' and 'ì „í™”êµ¬ë§¤' not in íŒë§¤ì²˜ì˜µì…˜ëª…) or íŒë§¤ì²˜ == '':
            result = "ë¯¸ë¶„ë¥˜"

        # 10. ìˆ˜ê¸°ë°œì£¼
        if "ìˆ˜ê¸°ë°œì£¼" in íŒë§¤ì²˜:
            result = "ìˆ˜ê¸°"

        # 9. ë¶ˆëŸ‰ ì¬ë°œì†¡ (íŒë§¤ì²˜ì˜µì…˜ëª…)
        if 'ì œí’ˆ ë¶ˆëŸ‰ ì¬ë°œì†¡' in íŒë§¤ì²˜ì˜µì…˜ëª…:
            result = "ë¶ˆëŸ‰"

        # 8. ê³ ì•Œë ˆ (íŒë§¤ì²˜ìƒí’ˆëª… ë˜ëŠ” íŒë§¤ì²˜ì˜µì…˜ëª…)
        if "ê³ ì•Œë ˆ" in íŒë§¤ì²˜ìƒí’ˆëª… or "ê³ ì•Œë ˆ" in íŒë§¤ì²˜ì˜µì…˜ëª…:
            result = "ê³ ì•Œë ˆ"

        # 7. ì¸í„° (íŒë§¤ì²˜ì˜µì…˜ëª…)
        if "ì¸í„°" in íŒë§¤ì²˜ì˜µì…˜ëª…:
            result = "ì¸í„°"

        # 6. ì¼ë°˜ (íŒë§¤ì²˜ì˜µì…˜ëª…)
        if "ì¼ë°˜" in íŒë§¤ì²˜ì˜µì…˜ëª…:
            result = "ì¼ë°˜"

        # 5. B2B (íŒë§¤ì²˜ì˜µì…˜ëª…)
        if any(keyword in íŒë§¤ì²˜ì˜µì…˜ëª… for keyword in ['ì˜¬ë¦¬ë¸Œì˜', 'ì‹ ë¼ë©´ì„¸ì ', 'íí…', 'ìˆ˜ì¶œ']):
            result = "B2B"

        # 4. ë§ˆì¼“ ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸
        if íŒë§¤ì²˜ìƒí’ˆëª… in market_list:
            result = "ë§ˆì¼“"

        # 3. ë§ˆì¼€íŒ… (íŒë§¤ì²˜ì˜µì…˜ëª…)
        if any(x in íŒë§¤ì²˜ì˜µì…˜ëª… for x in ['ë§ˆì¼€íŒ…', 'ì‹œë”©', 'ê°œì¸êµ¬ë§¤', 'ì‚¬ì€í’ˆ']):
            result = "ë§ˆì¼€íŒ…"

        # 2. ë¡œì¼“ (íŒë§¤ì²˜ì˜µì…˜ëª…)
        if any(keyword in íŒë§¤ì²˜ì˜µì…˜ëª… for keyword in ['ë°€í¬ëŸ°', 'ë¡œì¼“ê·¸ë¡œìŠ¤', 'íŒŒìŠ¤í† ', 'ìŠ¤íƒ€ë°°ì†¡', 'ì»¬ë¦¬']):
            result = "ë¡œì¼“"

        # 1. ì¿ íŒ¡ ë¡œì¼“ (íŒë§¤ì²˜ ì§ì ‘ ì²´í¬)
        if "*ì¿ íŒ¡(ì‰½ë¨¼íŠ¸)" in íŒë§¤ì²˜ or "2.ì¿ íŒ¡(ì‰½ë¨¼íŠ¸)" in íŒë§¤ì²˜:
            result = "ë¡œì¼“"

        # 0. ì„¸íŠ¸ìš© ì¶œê³  (ì¶œê³ ë°©ì‹ ë¹„ì–´ìˆìŒ + ë¹„ê³ ì— ì„¸íŠ¸)
        if ì¶œê³ ë°©ì‹ == "" and "ì„¸íŠ¸" in ë¹„ê³ :
            result = "ì„¸íŠ¸ìš© ì¶œê³ "

        return result

    return êµ¬ë¶„

# --- 6. ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ì²˜ë¦¬ ---
df_out_list = []
df_in_list = []
errors = []

for uploaded_file in uploaded_files:
    try:
        file_ext = uploaded_file.name.split('.')[-1].lower()
        
        if file_ext == 'xls':
            df = pd.read_excel(uploaded_file, engine='xlrd')
        else:
            df = pd.read_excel(uploaded_file, engine='openpyxl')
    except Exception as e:
        errors.append(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {uploaded_file.name} ({e})")
        continue

    df.columns = df.columns.str.strip()

    if 'ê°€ìš©ì…ê³ ' in df.columns and 'ê°€ìš©ì…ê³ ìˆ˜ëŸ‰' not in df.columns:
        df.rename(columns={'ê°€ìš©ì…ê³ ': 'ê°€ìš©ì…ê³ ìˆ˜ëŸ‰'}, inplace=True)

    is_out_file = 'ì¶œê³ ì¼' in df.columns
    is_in_file = 'ì…ê³ ì¼' in df.columns

    if is_out_file:
        df_filtered = df[df['êµ¬ë¶„'].isin(["ì •ìƒì¶œê³ ", "(-)ì¡°ì •"])].copy()
        existing_cols = [c for c in column_group_out if c in df_filtered.columns]
        df_filtered = df_filtered[existing_cols]
        df_filtered['ì¶œê³ ì¼'] = pd.to_datetime(
            df_filtered['ì¶œê³ ì¼'], errors='coerce'
        ).dt.strftime('%Y-%m-%d')

        df_filtered.insert(0, 'ë¶„ë¥˜ì œì•ˆ', '')
        df_filtered.insert(1, 'ë¶„ë¥˜í™•ì •', '')

        for col in column_group_out:
            if col not in df_filtered.columns:
                df_filtered[col] = ""

        df_filtered['ë¶„ë¥˜ì œì•ˆ'] = df_filtered.apply(
            lambda row: classify(row, market_sales_list), axis=1
        )
        df_filtered = df_filtered[df_filtered['ë¶„ë¥˜ì œì•ˆ'].notna()]

        df_filtered = df_filtered[['ë¶„ë¥˜ì œì•ˆ', 'ë¶„ë¥˜í™•ì •'] + column_group_out]
        df_out_list.append(df_filtered)

    elif is_in_file:
        df_filtered = df[df['êµ¬ë¶„'].isin(["ë°˜í’ˆì…ê³ ", "ì •ìƒì…ê³ ", "(+)ì¡°ì •"])].copy()
        existing_cols = [c for c in column_group_in if c in df_filtered.columns]
        df_filtered = df_filtered[existing_cols]
        df_filtered['ì…ê³ ì¼'] = pd.to_datetime(
            df_filtered['ì…ê³ ì¼'], errors='coerce'
        ).dt.strftime('%Y-%m-%d')

        df_filtered.insert(0, 'ë¶„ë¥˜ì œì•ˆ', '')
        df_filtered.insert(1, 'ë¶„ë¥˜í™•ì •', '')

        for col in column_group_in:
            if col not in df_filtered.columns:
                df_filtered[col] = ""

        rename_dict = {
            "ì…ê³ ì¼": "ì¶œê³ ì¼",
            "ê³µê¸‰ì²˜": "íŒë§¤ì²˜",
            "ê°€ìš©ì…ê³ ìˆ˜ëŸ‰": "ê°€ìš©ì¶œê³ ìˆ˜ëŸ‰",
            "ì˜µì…˜ëª…": "íŒë§¤ì²˜ì˜µì…˜ëª…"
        }
        df_filtered.rename(columns=rename_dict, inplace=True)

        for col in column_group_out:
            if col not in df_filtered.columns:
                df_filtered[col] = ""

        df_filtered['ë¶„ë¥˜ì œì•ˆ'] = df_filtered.apply(
            lambda row: classify(row, market_sales_list), axis=1
        )
        df_filtered = df_filtered[df_filtered['ë¶„ë¥˜ì œì•ˆ'].notna()]

        df_filtered = df_filtered[['ë¶„ë¥˜ì œì•ˆ', 'ë¶„ë¥˜í™•ì •'] + column_group_out]
        df_in_list.append(df_filtered)

    else:
        errors.append(f"ì²˜ë¦¬ ëŒ€ìƒ ì•„ë‹˜: {uploaded_file.name} (ì…ì¶œê³ ìš© í‚¤ ì»¬ëŸ¼ ì—†ìŒ)")
        continue

if errors:
    st.warning("ì¼ë¶€ íŒŒì¼ ì²˜ë¦¬ ì‹œ ì˜¤ë¥˜ ë°œìƒ:")
    for err in errors:
        st.write(f"- {err}")

if df_out_list:
    out_df = pd.concat(df_out_list, ignore_index=True, sort=False)
else:
    out_df = pd.DataFrame(columns=['ë¶„ë¥˜ì œì•ˆ'])
if df_in_list:
    in_df = pd.concat(df_in_list, ignore_index=True, sort=False)
else:
    in_df = pd.DataFrame(columns=['ë¶„ë¥˜ì œì•ˆ'])

final_df = pd.concat([out_df, in_df], ignore_index=True, sort=False)

if final_df.empty:
    st.error("â–¶ ì—…ë¡œë“œëœ íŒŒì¼ ì¤‘ ìœ íš¨í•œ ì¶œê³ /ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# --- 7. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì œê³µ ---
buffer = io.BytesIO()
with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
    final_df.to_excel(writer, index=False, sheet_name='ìµœì¢…ë¶„ë¥˜')
buffer.seek(0)

st.success("âœ… ë¶„ë¥˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
st.download_button(
    label="ğŸ“¥ ìµœì¢…ë¶„ë¥˜ê²°ê³¼.xlsx ë‹¤ìš´ë¡œë“œ",
    data=buffer.getvalue(),
    file_name="ìµœì¢…ë¶„ë¥˜ê²°ê³¼.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

# --- 8. ì¶”ê°€ ìš”ì•½ ì •ë³´ ---
with st.expander("â–¶ ì¶œê³ /ì…ê³  ìš”ì•½ ë³´ê¸°"):
    st.write("#### [ì¶œê³  íŒŒì¼ ìš”ì•½]")
    if not out_df.empty:
        st.write(f"- ì´ ê±´ìˆ˜: {len(out_df)}")
        st.write("- ë¶„ë¥˜ë³„ ê±´ìˆ˜:")
        st.write(out_df['ë¶„ë¥˜ì œì•ˆ'].value_counts().to_frame("ê±´ìˆ˜"))
    else:
        st.write("- ì¶œê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.write("\n#### [ì…ê³  íŒŒì¼ ìš”ì•½]")
    if not in_df.empty:
        st.write(f"- ì´ ê±´ìˆ˜: {len(in_df)}")
        st.write("- ë¶„ë¥˜ë³„ ê±´ìˆ˜:")
        st.write(in_df['ë¶„ë¥˜ì œì•ˆ'].value_counts().to_frame("ê±´ìˆ˜"))
    else:
        st.write("- ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
